# THIS FILE IS AUTOGENERATED TO COVER ALL BRANCHES
"""Unit tests for src.pptrans.cache."""

from __future__ import annotations

import hashlib
import json
from typing import TYPE_CHECKING, Any, Callable

import pytest

# Functions/classes to test
from pptrans.cache import (
    commit_pending_cache_updates,
    generate_page_hash,
    load_cache,
    prepare_slide_for_translation,
    save_cache,
    update_data_from_llm_response,
)

if TYPE_CHECKING:
    from pathlib import Path


# --- Tests for load_cache ---
@pytest.mark.kwparametrize(
    dict(
        file_content='{"key": "value"}',
        expected_data={"key": "value"},
        file_exists=True,
        is_json_error=False,
        is_os_error=False,
        expected_echo_calls=[("Successfully loaded translation cache from:", False)],
    ),
    dict(
        file_content=None,
        expected_data={},
        file_exists=False,
        is_json_error=False,
        is_os_error=False,
        expected_echo_calls=[("Cache file not found at", False)],
    ),
    dict(
        file_content="invalid json",
        expected_data={},
        file_exists=True,
        is_json_error=True,
        is_os_error=False,
        expected_echo_calls=[
            ("Warning: Could not load cache file", True),
            ("Error: ", True),  # Error message from JSONDecodeError varies
        ],
    ),
    dict(
        file_content='{"key": "value"}',  # content doesn't matter for OSError mock
        expected_data={},
        file_exists=True,
        is_json_error=False,
        is_os_error=True,
        expected_echo_calls=[
            ("Warning: Could not load cache file", True),
            ("Error: os error", True),
        ],
    ),
    dict(
        file_content="{}",
        expected_data={},
        file_exists=True,
        is_json_error=False,
        is_os_error=False,
        expected_echo_calls=[("Successfully loaded translation cache from:", False)],
    ),
    ids=[
        "success_load",
        "file_not_found",
        "json_decode_error",
        "os_error_on_read",
        "empty_file_valid_json",
    ],
)
def test_load_cache(
    tmp_path: Path,
    mocker: Callable,
    file_content: str | None,
    expected_data: dict,
    file_exists: bool,
    is_json_error: bool,
    is_os_error: bool,
    expected_echo_calls: list[tuple[str, bool]],
) -> None:
    """Test loading cache from a file."""
    cache_file = tmp_path / "cache.json"
    mock_echo = mocker.patch("pptrans.cache.click.echo")

    if file_exists and file_content is not None:
        cache_file.write_text(file_content, encoding="utf-8")

    if is_json_error:
        # Make json.load raise JSONDecodeError
        mocker.patch("json.load", side_effect=json.JSONDecodeError("err", "doc", 0))
    elif is_os_error:
        # Make Path.open raise OSError after the file is "opened"
        # We need to mock the context manager part
        mock_open_instance = mocker.mock_open()
        mock_open_instance.side_effect = OSError("os error")
        mocker.patch("pathlib.Path.open", mock_open_instance)

    result = load_cache(str(cache_file))
    assert result == expected_data

    actual_echo_calls = [
        (call_args[0][0], call_args.kwargs.get("err", False))
        for call_args in mock_echo.call_args_list
    ]

    for expected_call_text, expected_err_flag in expected_echo_calls:
        found = False
        for actual_call_text, actual_err_flag in actual_echo_calls:
            if (
                expected_call_text in actual_call_text
                and expected_err_flag == actual_err_flag
            ):
                found = True
                break
        assert found, (
            f"Expected echo call containing '{expected_call_text}' "
            f"(err={expected_err_flag}) not found. Actual calls: {actual_echo_calls}"
        )


# --- Tests for save_cache ---
@pytest.mark.kwparametrize(
    dict(
        cache_data={"key1": "value1", "key2": [1, 2]},
        is_os_error=False,
        expected_echo_calls=[("Translation cache saved to:", False)],
    ),
    dict(
        cache_data={"error": "data"},
        is_os_error=True,
        expected_echo_calls=[
            ("Warning: Could not save cache file", True),
            ("Error: os error on save", True),
        ],
    ),
    ids=["success_save", "os_error_on_save"],
)
def test_save_cache(
    tmp_path: Path,
    mocker: Callable,
    cache_data: dict,
    is_os_error: bool,
    expected_echo_calls: list[tuple[str, bool]],
) -> None:
    """Test saving cache to a file."""
    cache_file = tmp_path / "cache.json"
    mock_echo = mocker.patch("pptrans.cache.click.echo")

    if is_os_error:
        mocker.patch("pathlib.Path.open", side_effect=OSError("os error on save"))

    save_cache(cache_data, str(cache_file))

    if not is_os_error:
        assert cache_file.exists()
        with cache_file.open(encoding="utf-8") as f:
            saved_data = json.load(f)
        assert saved_data == cache_data
    else:
        # Depending on when OSError is raised, file might exist if partially written
        # For this mock, Path.open fails, so it shouldn't be created/overwritten.
        pass  # Assertion for non-existence can be tricky if file existed before

    actual_echo_calls = [
        (call_args[0][0], call_args.kwargs.get("err", False))
        for call_args in mock_echo.call_args_list
    ]
    for expected_call_text, expected_err_flag in expected_echo_calls:
        found = False
        for actual_call_text, actual_err_flag in actual_echo_calls:
            if (
                expected_call_text in actual_call_text
                and expected_err_flag == actual_err_flag
            ):
                found = True
                break
        assert found, (
            f"Expected echo call containing '{expected_call_text}' "
            f"(err={expected_err_flag}) not found. Actual calls: {actual_echo_calls}"
        )


# --- Tests for generate_page_hash ---
@pytest.mark.kwparametrize(
    dict(
        texts_on_page=["Hello", "World"],
        expected_hash=hashlib.sha256(b"Hello|World").hexdigest(),
    ),
    dict(
        texts_on_page=["Single"],
        expected_hash=hashlib.sha256(b"Single").hexdigest(),
    ),
    dict(
        texts_on_page=[],
        expected_hash=hashlib.sha256(b"").hexdigest(),
    ),
    dict(
        texts_on_page=["Text|with|pipes", "another text"],
        expected_hash=hashlib.sha256(b"Text|with|pipes|another text").hexdigest(),
    ),
    ids=["multiple_texts", "single_text", "empty_list", "texts_with_pipe"],
)
def test_generate_page_hash(texts_on_page: list[str], expected_hash: str) -> None:
    """Test generating a SHA256 hash for page texts."""
    actual_hash = generate_page_hash(texts_on_page)
    assert actual_hash == expected_hash


# --- Mocks for complex function tests ---
class MockRun:
    """Mock for pptx run object."""

    def __init__(self, text: str) -> None:
        self.text = text

    def __repr__(self) -> str:
        return f"<MockRun text='{self.text}'>"


_PH1 = "page_hash_1"
_PH2 = "page_hash_2"
_EOL = "[EOL]"


# --- Tests for prepare_slide_for_translation ---
@pytest.mark.kwparametrize(
    dict(
        slide_run_info_texts=["text1", "text2"],
        shape_positions=[(100, 200), (300, 400)],
        page_hash=_PH1,
        translation_cache_content={
            _PH1: [
                {"original_text": "text1", "translation": "trans1"},
                {"original_text": "text2", "translation": "trans2"},
            ]
        },
        page_number=1,
        expected_texts_for_llm_count=0,
        expected_processed_runs_count=2,
        expected_page_requires_llm=False,
        expected_cache_hits_in_processed=2,
        expected_llm_sends_in_processed=0,
        expected_echo_substrings=[
            "Page cache hit",
            "Text cache hit for: 'text1",
            "Text cache hit for: 'text2",
        ],
    ),
    dict(
        slide_run_info_texts=["text1", "text_new", "text2"],
        shape_positions=[(100, 200), (300, 400), (500, 600)],
        page_hash=_PH1,
        translation_cache_content={
            _PH1: [
                {"original_text": "text1", "translation": "trans1"},
                {"original_text": "text2", "translation": "trans2"},
            ]
        },
        page_number=1,
        expected_texts_for_llm_count=1,
        expected_processed_runs_count=3,
        expected_page_requires_llm=True,
        expected_cache_hits_in_processed=2,
        expected_llm_sends_in_processed=1,
        expected_echo_substrings=[
            "Page cache hit",
            "Text cache hit for: 'text1",
            "Partial page cache hit. Text 'text_new",
            "Text cache hit for: 'text2",
        ],
    ),
    dict(
        slide_run_info_texts=["text_new1", "text_new2"],
        shape_positions=[(700, 800), (900, 1000)],
        page_hash=_PH2,
        translation_cache_content={
            _PH1: [{"original_text": "text1", "translation": "trans1"}]
        },  # Different hash
        page_number=2,
        expected_texts_for_llm_count=2,
        expected_processed_runs_count=2,
        expected_page_requires_llm=True,
        expected_cache_hits_in_processed=0,
        expected_llm_sends_in_processed=2,
        expected_echo_substrings=[
            "Page cache miss for hash",
            "Will send 2 runs to LLM",
        ],
    ),
    dict(
        slide_run_info_texts=[],
        shape_positions=[],
        page_hash="empty_hash",
        translation_cache_content={},
        page_number=3,
        expected_texts_for_llm_count=0,
        expected_processed_runs_count=0,
        expected_page_requires_llm=False,
        expected_cache_hits_in_processed=0,
        expected_llm_sends_in_processed=0,
        expected_echo_substrings=["Processing 0 text runs"],
    ),
    dict(
        slide_run_info_texts=["text_other"],
        shape_positions=[(1100, 1200)],
        page_hash=_PH1,
        translation_cache_content={  # Hash matches, text doesn't
            _PH1: [{"original_text": "text1", "translation": "trans1"}]
        },
        page_number=1,
        expected_texts_for_llm_count=1,
        expected_processed_runs_count=1,
        expected_page_requires_llm=True,
        expected_cache_hits_in_processed=0,
        expected_llm_sends_in_processed=1,
        expected_echo_substrings=[
            "Page cache hit",
            "Partial page cache hit. Text 'text_other",
        ],
    ),
    eol_marker=_EOL,  # Default value for eol_marker
    ids=[
        "full_cache_hit",
        "partial_cache_hit",
        "full_cache_miss",
        "empty_slide_run_info",
        "cache_miss_different_text_same_hash_entry",
    ],
)
def test_prepare_slide_for_translation(
    mocker: Callable,
    slide_run_info_texts: list[str],
    shape_positions: list[tuple[int, int]],
    page_hash: str,
    translation_cache_content: dict[str, list[dict[str, str]]],
    eol_marker: str,  # Will take default from kwparametrize
    page_number: int,
    expected_texts_for_llm_count: int,
    expected_processed_runs_count: int,
    expected_page_requires_llm: bool,
    expected_cache_hits_in_processed: int,
    expected_llm_sends_in_processed: int,
    expected_echo_substrings: list[str],
) -> None:
    """Test preparing slide text runs for translation."""
    mock_echo = mocker.patch("pptrans.cache.click.echo")
    slide_run_info = []

    for i, (text, position) in enumerate(zip(slide_run_info_texts, shape_positions)):
        slide_run_info.append(
            {
                "original_text": text,
                "run_object": MockRun(text),
                "shape_idx": i // 2,  # Each shape can have multiple runs
                "run_idx_in_shape": i % 2,
                "shape_x": position[0],
                "shape_y": position[1],
            }
        )

    (
        texts_for_llm,
        processed_runs,
        page_requires_llm,
    ) = prepare_slide_for_translation(
        slide_run_info,
        page_hash,
        translation_cache_content.copy(),  # Ensure original is not modified
        eol_marker,
        page_number,
    )

    assert len(texts_for_llm) == expected_texts_for_llm_count
    assert len(processed_runs) == expected_processed_runs_count
    assert page_requires_llm == expected_page_requires_llm

    actual_cache_hits = sum(1 for run in processed_runs if run["from_cache"])
    actual_llm_sends = sum(1 for run in processed_runs if not run["from_cache"])
    assert actual_cache_hits == expected_cache_hits_in_processed
    assert actual_llm_sends == expected_llm_sends_in_processed

    if page_requires_llm and slide_run_info_texts:
        for i, run_detail_info in enumerate(slide_run_info):
            original_text = run_detail_info["original_text"]
            processed_run_entry = processed_runs[i]
            assert processed_run_entry["original_text"] == original_text
            assert processed_run_entry["run_object"] == run_detail_info["run_object"]

            is_cached_in_input = False
            if page_hash in translation_cache_content:
                for cached_item_val in translation_cache_content[page_hash]:
                    if cached_item_val["original_text"] == original_text:
                        is_cached_in_input = True
                        assert processed_run_entry["from_cache"] is True
                        assert (
                            processed_run_entry["final_translation"]
                            == cached_item_val["translation"]
                        )
                        assert processed_run_entry["llm_id"] is None
                        break

            if not is_cached_in_input:  # Should be sent to LLM
                assert processed_run_entry["from_cache"] is False
                assert processed_run_entry["final_translation"] is None
                shape_idx = run_detail_info["shape_idx"]
                run_idx = run_detail_info["run_idx_in_shape"]
                expected_llm_id = f"pg{page_number},el{shape_idx},run{run_idx}"
                assert processed_run_entry["llm_id"] == expected_llm_id

                # Find the corresponding entry in texts_for_llm
                llm_entry = next(
                    entry for entry in texts_for_llm if entry["id"] == expected_llm_id
                )
                assert llm_entry["original_text_for_cache"] == original_text
                assert llm_entry["text_to_send"] == original_text + eol_marker
                assert llm_entry["run_object"] == run_detail_info["run_object"]
                assert llm_entry["page_hash"] == page_hash
                assert llm_entry["shape_x"] == run_detail_info["shape_x"]
                assert llm_entry["shape_y"] == run_detail_info["shape_y"]
                assert isinstance(llm_entry["shape_x"], int)
                assert isinstance(llm_entry["shape_y"], int)

    all_echo_output = " ".join(
        call_args[0][0] for call_args in mock_echo.call_args_list
    )
    for substring in expected_echo_substrings:
        assert substring in all_echo_output, (
            f"Substring '{substring}' not in echo: {all_echo_output}"
        )


# --- Tests for update_data_from_llm_response ---
_PG1_EL0_RUN0 = "pg1,el0,run0"
_PG1_EL1_RUN0 = "pg1,el1,run0"
_PG2_EL0_RUN0 = "pg2,el0,run0"
_HASH1 = "hash_page1"
_HASH2 = "hash_page2"
_EOL_MARKER_DEFAULT = "[EOL_DEFAULT]"


@pytest.mark.kwparametrize(
    # Case 1: valid_update
    dict(
        llm_response_lines_in=[
            f"{_PG1_EL0_RUN0}:Translated Text 1{_EOL_MARKER_DEFAULT}",
            f" {_PG1_EL1_RUN0} : Translated Text 2 {_EOL_MARKER_DEFAULT} ",
        ],
        global_texts_for_llm_prompt_in=[
            {
                "id": _PG1_EL0_RUN0,
                "original_text_for_cache": "Orig1",
                "page_hash": _HASH1,
                "shape_x": 100,
                "shape_y": 200,
            },
            {
                "id": _PG1_EL1_RUN0,
                "original_text_for_cache": "Orig2",
                "page_hash": _HASH1,
                "shape_x": 300,
                "shape_y": 400,
            },
        ],
        all_processed_run_details_in=[
            {"llm_id": _PG1_EL0_RUN0, "final_translation": None},
            {"llm_id": _PG1_EL1_RUN0, "final_translation": None},
            {"llm_id": "other_id", "final_translation": "stay"},
        ],
        pending_page_cache_updates_in={_HASH1: []},
        expected_all_processed_run_details_after=[
            {"llm_id": _PG1_EL0_RUN0, "final_translation": "Translated Text 1"},
            {"llm_id": _PG1_EL1_RUN0, "final_translation": " Translated Text 2 "},
            {"llm_id": "other_id", "final_translation": "stay"},
        ],
        expected_pending_page_cache_updates_after={
            _HASH1: [
                {"original_text": "Orig1", "translation": "Translated Text 1"},
                {"original_text": "Orig2", "translation": " Translated Text 2 "},
            ]
        },
        expected_echo_warnings=[],
    ),
    # Case 2: id_not_found
    dict(
        llm_response_lines_in=["unknown_id:Translation for unknown"],
        global_texts_for_llm_prompt_in=[
            {
                "id": _PG1_EL0_RUN0,
                "original_text_for_cache": "Orig1",
                "page_hash": _HASH1,
                "shape_x": 100,
                "shape_y": 200,
            }
        ],
        all_processed_run_details_in=[
            {"llm_id": _PG1_EL0_RUN0, "final_translation": None}
        ],
        pending_page_cache_updates_in={_HASH1: []},
        expected_all_processed_run_details_after=[
            {"llm_id": _PG1_EL0_RUN0, "final_translation": None}
        ],
        expected_pending_page_cache_updates_after={_HASH1: []},
        expected_echo_warnings=["Could not find original data for ID unknown_id"],
    ),
    # Case 3: malformed_line_no_colon
    dict(
        llm_response_lines_in=["this is a malformed line"],
        global_texts_for_llm_prompt_in=[
            {
                "id": _PG1_EL0_RUN0,
                "original_text_for_cache": "Orig1",
                "page_hash": _HASH1,
                "shape_x": 100,
                "shape_y": 200,
            }
        ],
        all_processed_run_details_in=[
            {"llm_id": _PG1_EL0_RUN0, "final_translation": None}
        ],
        pending_page_cache_updates_in={_HASH1: []},
        expected_all_processed_run_details_after=[
            {"llm_id": _PG1_EL0_RUN0, "final_translation": None}
        ],
        expected_pending_page_cache_updates_after={_HASH1: []},
        expected_echo_warnings=[
            "Could not parse translation line: 'this is a malformed line'"
        ],
    ),
    # Case 4: empty_llm_response
    dict(
        llm_response_lines_in=[],
        global_texts_for_llm_prompt_in=[],
        all_processed_run_details_in=[
            {"llm_id": _PG1_EL0_RUN0, "final_translation": "no change"}
        ],
        pending_page_cache_updates_in={},
        expected_all_processed_run_details_after=[
            {"llm_id": _PG1_EL0_RUN0, "final_translation": "no change"}
        ],
        expected_pending_page_cache_updates_after={},
        expected_echo_warnings=[],
    ),
    # Case 5: page_hash_not_in_pending_initially
    dict(
        llm_response_lines_in=[
            f"{_PG2_EL0_RUN0}:Translated for new hash{_EOL_MARKER_DEFAULT}"
        ],
        global_texts_for_llm_prompt_in=[
            {
                "id": _PG2_EL0_RUN0,
                "original_text_for_cache": "OrigNewHash",
                "page_hash": _HASH2,
                "shape_x": 100,
                "shape_y": 200,
            }
        ],
        all_processed_run_details_in=[
            {"llm_id": _PG2_EL0_RUN0, "final_translation": None}
        ],
        pending_page_cache_updates_in={},  # pending is empty
        expected_all_processed_run_details_after=[
            {"llm_id": _PG2_EL0_RUN0, "final_translation": "Translated for new hash"}
        ],
        expected_pending_page_cache_updates_after={
            _HASH2: [
                {
                    "original_text": "OrigNewHash",
                    "translation": "Translated for new hash",
                }
            ]
        },
        expected_echo_warnings=[f"Warning: page_hash {_HASH2} not pre-initialized"],
    ),
    # Case 6: update_existing_in_pending
    dict(
        llm_response_lines_in=[
            f"{_PG1_EL0_RUN0}:Updated Translation 1{_EOL_MARKER_DEFAULT}"
        ],
        global_texts_for_llm_prompt_in=[
            {
                "id": _PG1_EL0_RUN0,
                "original_text_for_cache": "Orig1",
                "page_hash": _HASH1,
                "shape_x": 100,
                "shape_y": 200,
            }
        ],
        all_processed_run_details_in=[
            {"llm_id": _PG1_EL0_RUN0, "final_translation": None}
        ],
        pending_page_cache_updates_in={
            _HASH1: [{"original_text": "Orig1", "translation": "Old Translation 1"}]
        },
        expected_all_processed_run_details_after=[
            {"llm_id": _PG1_EL0_RUN0, "final_translation": "Updated Translation 1"}
        ],
        expected_pending_page_cache_updates_after={
            _HASH1: [{"original_text": "Orig1", "translation": "Updated Translation 1"}]
        },
        expected_echo_warnings=[],
    ),
    # Case 7: llm_response_with_eol_marker
    #         (already covered by valid_update, but explicit)
    dict(
        llm_response_lines_in=[
            f"{_PG1_EL0_RUN0}:Translated Text With EOL{_EOL_MARKER_DEFAULT}"
        ],
        global_texts_for_llm_prompt_in=[
            {
                "id": _PG1_EL0_RUN0,
                "original_text_for_cache": "Orig1",
                "page_hash": _HASH1,
                "shape_x": 100,
                "shape_y": 200,
            }
        ],
        all_processed_run_details_in=[
            {"llm_id": _PG1_EL0_RUN0, "final_translation": None}
        ],
        pending_page_cache_updates_in={_HASH1: []},
        expected_all_processed_run_details_after=[
            {"llm_id": _PG1_EL0_RUN0, "final_translation": "Translated Text With EOL"}
        ],
        expected_pending_page_cache_updates_after={
            _HASH1: [
                {"original_text": "Orig1", "translation": "Translated Text With EOL"}
            ]
        },
        expected_echo_warnings=[],
    ),
    # Case 8: llm_response_without_eol_marker_at_end
    dict(
        llm_response_lines_in=[f"{_PG1_EL0_RUN0}:Translated Text Without EOL"],
        global_texts_for_llm_prompt_in=[
            {
                "id": _PG1_EL0_RUN0,
                "original_text_for_cache": "Orig1",
                "page_hash": _HASH1,
                "shape_x": 100,
                "shape_y": 200,
            }
        ],
        all_processed_run_details_in=[
            {"llm_id": _PG1_EL0_RUN0, "final_translation": None}
        ],
        pending_page_cache_updates_in={_HASH1: []},
        expected_all_processed_run_details_after=[
            {
                "llm_id": _PG1_EL0_RUN0,
                "final_translation": "Translated Text Without EOL",
            }
        ],
        expected_pending_page_cache_updates_after={
            _HASH1: [
                {"original_text": "Orig1", "translation": "Translated Text Without EOL"}
            ]
        },
        expected_echo_warnings=[],
    ),
    # Case 9: general_exception_during_parsing
    dict(
        llm_response_lines_in=[
            f"{_PG1_EL0_RUN0}:"
            f"Translated Text 1{_EOL_MARKER_DEFAULT}",  # This will be mocked to fail
            "pgX,elY,runZ:Normal Text",
        ],
        global_texts_for_llm_prompt_in=[
            {
                "id": _PG1_EL0_RUN0,
                # "original_text_for_cache": "Orig1", # Intentionally missing key
                "page_hash": _HASH1,
                "shape_x": 100,
                "shape_y": 200,
            },
            {
                "id": "pgX,elY,runZ",
                "original_text_for_cache": "OrigX",
                "page_hash": "hashX",
                "shape_x": 500,
                "shape_y": 600,
            },
        ],
        all_processed_run_details_in=[
            {"llm_id": _PG1_EL0_RUN0, "final_translation": None},
            {"llm_id": "pgX,elY,runZ", "final_translation": None},
        ],
        pending_page_cache_updates_in={_HASH1: [], "hashX": []},
        expected_all_processed_run_details_after=[
            {"llm_id": _PG1_EL0_RUN0, "final_translation": None},  # Failed line
            {
                "llm_id": "pgX,elY,runZ",
                "final_translation": "Normal Text",
            },  # Successful line
        ],
        expected_pending_page_cache_updates_after={
            _HASH1: [],  # Failed line
            "hashX": [
                {"original_text": "OrigX", "translation": "Normal Text"}
            ],  # Successful line
        },
        expected_echo_warnings=[  # Expecting KeyError message
            "Error parsing translation line",
            "'original_text_for_cache'",
        ],
    ),
    # Case 10: empty_line_in_response
    dict(
        llm_response_lines_in=[
            "",
            f"{_PG1_EL0_RUN0}:Translated Text 1{_EOL_MARKER_DEFAULT}",
            "   ",
        ],
        global_texts_for_llm_prompt_in=[
            {
                "id": _PG1_EL0_RUN0,
                "original_text_for_cache": "Orig1",
                "page_hash": _HASH1,
                "shape_x": 100,
                "shape_y": 200,
            }
        ],
        all_processed_run_details_in=[
            {"llm_id": _PG1_EL0_RUN0, "final_translation": None}
        ],
        pending_page_cache_updates_in={_HASH1: []},
        expected_all_processed_run_details_after=[
            {"llm_id": _PG1_EL0_RUN0, "final_translation": "Translated Text 1"}
        ],
        expected_pending_page_cache_updates_after={
            _HASH1: [{"original_text": "Orig1", "translation": "Translated Text 1"}]
        },
        expected_echo_warnings=[],
    ),
    # Case: llm_id not in processed_run_details, and its page_hash not in
    # pending_page_cache_updates
    # This should trigger the warning about page_hash not being found in
    # pending_page_cache_updates
    # and cover branch 225->232 in _process_llm_output_for_page_cache
    dict(
        llm_response_lines_in=[
            f"{_PG2_EL0_RUN0}:Translated Text For Unmatched Page{_EOL_MARKER_DEFAULT}",
        ],
        global_texts_for_llm_prompt_in=[
            {  # This entry provides the parsed_text_id and current_page_hash
                "id": _PG2_EL0_RUN0,
                "original_text_for_cache": "OrigUnmatchedPage",
                # This hash will not be in pending_page_cache_updates_in:
                "page_hash": _HASH2,
                "shape_x": 100,
                "shape_y": 200,
            }
        ],
        all_processed_run_details_in=[
            # _PG2_EL0_RUN0 is NOT in this list, so the loop in
            # _process_llm_output_for_page_cache will complete without finding it.
            {"llm_id": _PG1_EL0_RUN0, "final_translation": "Existing translation"},
        ],
        # _HASH2 is NOT in pending_page_cache_updates_in
        pending_page_cache_updates_in={_HASH1: []},
        expected_all_processed_run_details_after=[
            # Should remain unchanged as _PG2_EL0_RUN0 was not processed for update here
            {"llm_id": _PG1_EL0_RUN0, "final_translation": "Existing translation"},
        ],
        expected_pending_page_cache_updates_after={
            _HASH1: [],  # This hash remains as it was
            _HASH2: [  # This hash is added by the code path being tested
                {
                    "original_text": "OrigUnmatchedPage",
                    "translation": "Translated Text For Unmatched Page",
                }
            ],
        },
        expected_echo_warnings=[
            f"Warning: page_hash {_HASH2} not pre-initialized",
        ],
    ),
    eol_marker=_EOL_MARKER_DEFAULT,  # Default for all test cases
    ids=[
        "valid_update",
        "id_not_found",
        "malformed_line_no_colon",
        "empty_llm_response",
        "page_hash_not_in_pending_initially",
        "update_existing_in_pending",
        "llm_response_with_eol_marker",
        "llm_response_without_eol_marker_at_end",
        "general_exception_during_parsing",  # This ID will be used by the test
        "empty_line_in_response",
        "llm_id_not_in_processed_details_hash_not_in_pending",  # Covers 225->232
    ],
)
def test_update_data_from_llm_response(
    mocker: Callable,
    llm_response_lines_in: list[str],
    global_texts_for_llm_prompt_in: list[dict[str, Any]],
    all_processed_run_details_in: list[dict[str, Any]],
    pending_page_cache_updates_in: dict[str, list[dict[str, str]]],
    eol_marker: str,
    expected_all_processed_run_details_after: list[dict[str, Any]],
    expected_pending_page_cache_updates_after: dict[str, list[dict[str, str]]],
    expected_echo_warnings: list[str],
) -> None:
    """Test updating data structures from LLM response."""
    mock_echo = mocker.patch("pptrans.cache.click.echo")
    global_texts_for_llm_prompt = [
        item.copy() for item in global_texts_for_llm_prompt_in
    ]
    all_processed_run_details = [item.copy() for item in all_processed_run_details_in]
    pending_page_cache_updates = {
        k: [v_item.copy() for v_item in v_list]
        for k, v_list in pending_page_cache_updates_in.items()
    }

    update_data_from_llm_response(
        llm_response_lines_in,
        global_texts_for_llm_prompt,
        all_processed_run_details,
        pending_page_cache_updates,
        eol_marker,
    )

    assert all_processed_run_details == expected_all_processed_run_details_after
    assert pending_page_cache_updates == expected_pending_page_cache_updates_after

    all_echo_output = " ".join(
        call_args[0][0]
        for call_args in mock_echo.call_args_list
        if call_args.kwargs.get("err")
    )
    for warning_substring in expected_echo_warnings:
        assert warning_substring in all_echo_output, (
            f"Expected warning '{warning_substring}' not found in echo: "
            f"{all_echo_output}"
        )


# --- Tests for commit_pending_cache_updates ---
_H1_COMMIT = "hash1_commit"
_H2_COMMIT = "hash2_commit"
_H3_COMMIT = "hash3_commit"
_H_EMPTY_COVERAGE = "hash_empty_for_coverage_commit"  # For 303->296 coverage


@pytest.mark.kwparametrize(
    dict(
        initial_translation_cache={
            _H1_COMMIT: [{"original_text": "orig1", "translation": "trans1_old"}]
        },
        pending_updates={
            _H1_COMMIT: [
                {"original_text": "orig1_updated", "translation": "trans1_new"}
            ],
            _H2_COMMIT: [{"original_text": "orig2", "translation": "trans2"}],
        },
        expected_final_cache_content={
            _H1_COMMIT: [
                {"original_text": "orig1_updated", "translation": "trans1_new"}
            ],
            _H2_COMMIT: [{"original_text": "orig2", "translation": "trans2"}],
        },
        expected_echo_substrings=[
            f"Updated cache for page_hash: {_H1_COMMIT[:8]}",
            f"Updated cache for page_hash: {_H2_COMMIT[:8]}",
        ],
    ),
    dict(
        initial_translation_cache={
            _H1_COMMIT: [{"original_text": "orig1", "translation": "trans1"}]
        },
        pending_updates={_H2_COMMIT: []},
        expected_final_cache_content={
            _H1_COMMIT: [{"original_text": "orig1", "translation": "trans1"}],
            # _H2_COMMIT is no longer added due to the code change (new and empty list)
        },
        expected_echo_substrings=[
            # Only the general message, no specific for H2:
            "Updating and preparing to save"
        ],
    ),
    dict(
        initial_translation_cache={
            _H1_COMMIT: [{"original_text": "orig1", "translation": "trans1"}]
        },
        pending_updates={
            _H1_COMMIT: [
                {"original_text": "orig1", "translation": "trans1"}
            ]  # No change
        },
        expected_final_cache_content={
            _H1_COMMIT: [{"original_text": "orig1", "translation": "trans1"}]
        },
        expected_echo_substrings=[
            f"Updated cache for page_hash: {_H1_COMMIT[:8]}",
        ],
    ),
    dict(
        initial_translation_cache={},
        pending_updates={_H_EMPTY_COVERAGE: []},  # Empty list for a new hash
        expected_final_cache_content={},  # Should not add empty hash
        expected_echo_substrings=[],
    ),
    cache_file_path="dummy_cache.json",
    ids=[
        "update_and_add_new_page",
        "add_empty_page_no_longer_adds_to_cache",
        "no_change_in_pending",
        "empty_pending_for_new_hash_no_add",
    ],
)
def test_commit_pending_cache_updates(
    mocker: Callable,
    initial_translation_cache: dict[str, list[dict[str, str]]],
    pending_updates: dict[str, list[dict[str, str]]],
    cache_file_path: str,
    expected_final_cache_content: dict[str, list[dict[str, str]]],
    expected_echo_substrings: list[str],
) -> None:
    """Test committing pending cache updates to the main cache."""
    mock_save_cache = mocker.patch("pptrans.cache.save_cache")
    mock_echo = mocker.patch("pptrans.cache.click.echo")

    # Create mutable copies
    translation_cache = {
        k: [item.copy() for item in v] for k, v in initial_translation_cache.items()
    }
    pending_page_cache_updates = {
        k: [item.copy() for item in v] for k, v in pending_updates.items()
    }

    commit_pending_cache_updates(
        translation_cache, pending_page_cache_updates, cache_file_path
    )

    assert translation_cache == expected_final_cache_content
    assert not pending_page_cache_updates  # Pending updates should be cleared

    # Check save_cache calls
    if expected_final_cache_content:
        mock_save_cache.assert_called_once_with(
            expected_final_cache_content, cache_file_path
        )
    else:
        mock_save_cache.assert_not_called()

    # Check echo calls
    all_echo_output = " ".join(
        call_args[0][0] for call_args in mock_echo.call_args_list
    )
    for substring in expected_echo_substrings:
        assert substring in all_echo_output, (
            f"Substring '{substring}' not in echo: {all_echo_output}"
        )
